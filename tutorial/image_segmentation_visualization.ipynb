{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:32.383997Z",
     "start_time": "2024-05-12T04:07:32.376096Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "plt.rcParams['savefig.bbox'] = 'tight'  # 保存图片时布局紧凑\n",
    "\n",
    "def show_image(images, title=None):\n",
    "    \"\"\"\n",
    "    显示图片\n",
    "    \"\"\"\n",
    "    if not isinstance(images, list):\n",
    "        images = [images]\n",
    "    # figure 表示整个图形，axes 表示包含每个子图坐标轴的数组，squeeze=False 表示始终返回一个二维数组\n",
    "    figure, axes = plt.subplots(ncols=len(images), squeeze=False)\n",
    "    \n",
    "    # 显示图片\n",
    "    for i, image in enumerate(images):\n",
    "        image = image.detach()\n",
    "        image = F.to_pil_image(image)\n",
    "        axes[0, i].imshow(np.asarray(image))\n",
    "        axes[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    \n",
    "    # 设置标题\n",
    "    if title:\n",
    "        figure.suptitle(title)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:32.398996Z",
     "start_time": "2024-05-12T04:07:32.386353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms\n",
    "\n",
    "def resize_and_center_crop(image, size=520):\n",
    "    \"\"\"\n",
    "    调整图片大小并裁剪中心区域\n",
    "    \"\"\"\n",
    "    image = F.resize(image, size)\n",
    "    image = F.center_crop(image, size)\n",
    "    return image"
   ],
   "id": "8f85b551b4c46c6e",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:32.853442Z",
     "start_time": "2024-05-12T04:07:32.400509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "\n",
    "# 读取图片\n",
    "image_path = '../datas/_TutorialImages/Segmentation'\n",
    "display_images = []\n",
    "for filename in os.listdir(image_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        path = os.path.join(image_path, filename)\n",
    "        # 读取图片\n",
    "        _image = read_image(path)\n",
    "        # 调整图片大小并裁剪中心区域\n",
    "        _image = resize_and_center_crop(_image)\n",
    "        display_images.append(_image)\n",
    "\n",
    "# 显示图片\n",
    "grid_image = make_grid(display_images)\n",
    "show_image(grid_image)"
   ],
   "id": "93f189eb14a4a18b",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:45.461596Z",
     "start_time": "2024-05-12T04:07:32.855588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "\n",
    "# 加载预训练模型\n",
    "weights = FCN_ResNet50_Weights.DEFAULT\n",
    "model = fcn_resnet50(weights=weights, progress=False)\n",
    "model.eval()\n",
    "\n",
    "# 预处理图片\n",
    "transform = weights.transforms()\n",
    "batch = torch.stack([transform(image) for image in display_images])\n",
    "\n",
    "# 推理\n",
    "with torch.no_grad():\n",
    "    output = model(batch)['out']"
   ],
   "id": "7fced9f350736e28",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:46.117809Z",
     "start_time": "2024-05-12T04:07:45.465866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "segmentation_class_to_idx = {cls: idx for idx, cls in enumerate(weights.meta['categories'])}\n",
    "\n",
    "normalized_masks = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "image_masks = [\n",
    "    normalized_masks[image_idx, segmentation_class_to_idx['dog']]\n",
    "    for image_idx in range(len(display_images))\n",
    "]\n",
    "\n",
    "show_image(image_masks)"
   ],
   "id": "8250081746f446e5",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:46.833369Z",
     "start_time": "2024-05-12T04:07:46.119201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_dim = 1\n",
    "boolean_dog_masks = (normalized_masks.argmax(class_dim) == segmentation_class_to_idx['dog'])\n",
    "show_image([m.float() for m in boolean_dog_masks])"
   ],
   "id": "d56ac60fd86281a1",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:47.817881Z",
     "start_time": "2024-05-12T04:07:46.835364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "class_dim = 1\n",
    "num_classes = len(weights.meta['categories'])\n",
    "all_classes_masks = normalized_masks.argmax(class_dim) == torch.arange(class_dim)[:, None, None, None]\n",
    "\n",
    "all_classes_masks = all_classes_masks.swapaxes(0, 1)\n",
    "dog_with_masks = [\n",
    "    draw_segmentation_masks(image, mask, alpha=0.7)\n",
    "    for image, mask in zip(display_images, all_classes_masks)\n",
    "]\n",
    "show_image(dog_with_masks)"
   ],
   "id": "ae27280620aa18c6",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:07:47.832632Z",
     "start_time": "2024-05-12T04:07:47.819951Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3c109996a34310b9",
   "execution_count": 18,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
